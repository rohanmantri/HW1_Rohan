---
title: "HW1"
author: "Rohan Mantri - rm58793"
date: "10/02/2022"
output: md_document
---

```{r echo=FALSE, message=FALSE, warning=FALSE}

library(tidyverse)
library(ggplot2)
library(data.table)
library(rsample)
library(caret)
library(modelr)
library(parallel)
library(foreach)
library(readr)
library(dplyr)

```

* Question I.

```{r echo=FALSE, message=FALSE, warning=FALSE}
ABIA <- read_csv("C:\\Users\\mantr\\Desktop\\Mona\\Masters\\Applications\\University of Texas at Austin\\Spring 22\\Data Mining\\Homework\\ABIA.csv")

ABIA$DepartureHour <- round(ABIA$DepTime/100, 0)
```


* Best time of the day to fly in or out of Austin is 5-7 AM

```{r echo=FALSE, message=FALSE, warning=FALSE}
ABIA %>%group_by(DepartureHour) %>% summarise(mean_dep_delay = mean(DepDelay, na.rm=TRUE)) %>% arrange(mean_dep_delay)
```


* The departure delay during the best time of the day to avoid delays (5-7AM) doesn't change that much for different Airlines

```{r echo=FALSE, message=FALSE, warning=FALSE}
mean_delay_by_hours <- ABIA %>% group_by(DepartureHour, UniqueCarrier) %>% summarise(mean_dep_delay = mean(DepDelay, na.rm=TRUE)) %>% arrange(mean_dep_delay) 

ggplot(mean_delay_by_hours) + geom_col(aes(x=DepartureHour, y=mean_dep_delay)) + facet_wrap(~UniqueCarrier) + labs(title = "Mean Departure Delay (Hours) by Airline") + xlab("Departure Time") + ylab("Mean Departure Delay")

```


* Best time of the year is Fall and Summer to fly in or out of Austin. We see high delays in Spring and Winter, maybe due to holidays.

```{r echo=FALSE, message=FALSE, warning=FALSE}
ABIA <- ABIA %>% mutate(Season = ifelse(ABIA$Month %in% c(12, 1, 2), "Winter", ifelse(ABIA$Month %in% c(3, 4, 5), "Spring", ifelse(ABIA$Month %in% c(6, 7, 8), "Summer", "Fall"))))

mean_dep_delay_by_season <- ABIA %>% group_by(Season, Dest) %>% summarise(mean_dep_delay = mean(DepDelay, na.rm=TRUE)) %>% arrange(mean_dep_delay) 

ggplot(mean_dep_delay_by_season, aes(Season, mean_dep_delay)) + geom_col()

```


* By grouping flying activities by destinations and sorting the data we observed that the top 6 most popular destinations are DAL (Dallas), DFW (Dallas), IAH (Houston), PHX (Pheonix), DEN (Denver), and ORD (Illinois). The bar graph shows high average departure delay in Spring especially for Dallas and Illinois. All of the 6 destinations commonly show least average departure delay in Fall.

```{r echo=FALSE, message=FALSE, warning=FALSE}
ABIA %>% group_by(Dest) %>% summarise(count = n()) %>% arrange(desc(count)) 

top_dest <- c("DAL", "DFW", "IAH", "PHX", "DEN", "ORD")

mean_dep_delay_by_season_top_dest <- mean_dep_delay_by_season %>% filter(Dest %in% top_dest)

ggplot(mean_dep_delay_by_season_top_dest, aes(Season, mean_dep_delay)) + geom_col() + facet_wrap(~Dest) + labs(title = "Mean Departure Delay by Top Destination for each Season") + xlab("Seasons") + ylab("Mean Departure Delay")

```

* Question 2A.

```{r echo=FALSE, message=FALSE, warning=FALSE}

billboard <- read.csv("C:\\Users\\mantr\\Desktop\\Mona\\Masters\\Applications\\University of Texas at Austin\\Spring 22\\Data Mining\\Homework\\billboard.csv")

billboard %>%
  group_by(song, performer) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  head(10)

```


* Caption: The top 10 most popular song since 1958 as measured by the total number of weeks that a song spent on the Billboard Top 100.
* Analysis: From the table, we see that Radioactive by Imagine Dragons is highly popular. It stayed on Billboard Top 100 for 87 weeks. Sail, Blinding Lights, and I'm Yours follow closely with the total number of weeks spent on the Billboard top 100 equal to 79, 76, and 76 respectively.

* Question 2B.

```{r echo=FALSE, message=FALSE, warning=FALSE}

plot_df = billboard %>% select(song_id, year) %>% distinct() %>% group_by(year) %>% count()
plot_df = plot_df %>% filter(year != 1958 & year != 2021)
plot(plot_df$year, plot_df$n, 'l', lwd = 2, col = "magenta",
     xlab = "Year", ylab = "Number of Distinct Songs by Year", 
     main = "Line Graph for Distinct Songs By a Given Year")

```

* Caption: Line graph showing number of unique songs each year from 1959 to 2020.
* Analysis: We see an increasing trend in musical diversity (as measured by number of unique songs) during 1960 and reached its peak at 1965. After that number of unique songs declined drastically and reached its lowest value of 400 in the year 2000. Then, the trend rose exponentially again until 2020.

* Question 2C.

```{r echo=FALSE, message=FALSE, warning=FALSE}

b = billboard %>% group_by(song_id, performer) %>% 
  summarize(noofweeks = n()) %>% 
  filter(noofweeks >= 10) %>% group_by(performer) %>% count() %>% filter(n >= 30)

ggplot(data = b, aes(y = performer, x = n, fill = as.factor(performer))) + geom_col() + labs(title = "Ten week hits on Billboard Top 100", caption = "The horizontal bar graph displaying total number of ten weeks hits for each 19 artists")

```

* Analysis: Ten weeks hit is for the songs that appear on Billboard Top 100 for at least 10 weeks. There are 19 artists with at least 30 songs on ten weeks hit. For example, Elton John had 52 songs on ten week hit, meaning, each of the 52 songs was featured on Billboard Top 100 for at least 10 weeks. Madonna had 44 songs on ten weeks hit followed by Kenny Chesney who had 42 songs.

* Question 3A.

```{r echo=FALSE, message=FALSE, warning=FALSE}

olympics_top20 <- read.csv("C:\\Users\\mantr\\Desktop\\Mona\\Masters\\Applications\\University of Texas at Austin\\Spring 22\\Data Mining\\Homework\\olympics_top20.csv")

h = olympics_top20 %>% filter(sex == 'F' & sport %like% "Athle") %>% 
  select(height)

quantile(h$height, c(.95))

```

* The 95th percentile of heights for female across all Athletics events is 183 cm. This means that 95% of the height for female across all Athletics events is 183 cm or lower.

* Question 3B.

```{r echo=FALSE, message=FALSE, warning=FALSE}

olympics_top20 %>% filter(sex == 'F') %>% select(height, event) %>%   
  group_by(event) %>% 
  summarize(stdev = sd(height)) %>% arrange(desc(stdev)) %>% 
  slice(c(1))

```
* Rowing Women's Coxed Fours had the greatest variability in competitor's height as measured by standard deviation of 10.9.

* Question 3C.

```{r echo=FALSE, message=FALSE, warning=FALSE}

av = olympics_top20 %>% filter(sport == 'Swimming') %>% 
  group_by(year, sex) %>% 
  summarize(avg = mean(age))
mal = av %>% filter(sex == 'M')
fem = av %>% filter(sex == 'F')

ggplot() + geom_line(data = mal, aes(x = year, y = avg, group = 1)) + 
  geom_point(data = mal, aes(x = year, y = avg, group = 1, color = sex)) +
  geom_line(data = fem, aes(x = year, y = avg, group = 1)) + 
  geom_point(data = fem, aes(x = year, y = avg, group = 1, color = sex)) +
  labs(title = "Average Age of Male and Female Olympic Swimmers")
  
```

* The trend for average age of Olympic swimmers fluctuated a lot since 1900. 
* The trend of the average age for Olympic male swimmers reached its peak in the year 1924 with the value of 32 years old. Then the average age dropped drastically and reached its minimum in the year 1932 with the value of 19 years old. After that, the trend has been rising slowly and reached the average age of 24.13 in the year 2016.
* The trend for women, on the other hand, remained low until 1975. Then it rose drastically to reach its peak value of 22.5 in 2000. After that, the average ages had been more or less constant at around 22 years old.
* The trends for male and female differed substantially and seemed to show no correlation. The average age for male reached its peak in the year 1924 with the value of 32 years old. While the average ages for women was highest in 2000 with the value of 22.5. Overall, the trend of average ages for men declined, plateaued and then increased at a decreasing rate  over time. On the contrary, the trend rose over time for women.

* Question 4.

```{r echo=FALSE, message=FALSE, warning=FALSE}
cars <- read.csv("C:\\Users\\mantr\\Desktop\\Mona\\Masters\\Applications\\University of Texas at Austin\\Spring 22\\Data Mining\\Homework\\sclass.csv")

cars_350 = cars %>% filter(trim == '350')

ggplot(data = cars_350) + 
  geom_point(mapping = aes(x = mileage, y = price), color='darkgrey') +
  labs(title = "Price of Trim=350 based on Mileage")

cars_350_split = initial_split(cars_350, prop=0.8)
cars_350_train = training(cars_350_split)
cars_350_test  = testing(cars_350_split)

k_grid = c(2, 4, 6, 8, 10, 15, 20, 25, 30, 35, 40, 45,
           50, 60, 70, 80, 90, 100)

k_grid = seq(2,100, by=1)

cv_350_grid = foreach(k = k_grid, .combine='rbind') %dopar% {
  knn = knnreg(price ~ mileage, data=cars_350_train, k=k)
  rms = rmse(knn, cars_350_test)
  c(k=k, err=rms)
} %>% as.data.frame

head(cv_350_grid)

ggplot(cv_350_grid) + 
  geom_point(aes(x=k, y=err)) +
  labs(title = "RMSE based on k")
  scale_x_log10()
  
cv_grid_output = cv_350_grid %>% filter(err == min(cv_350_grid$err))
cv_grid_output$k

knn = knnreg(price ~ mileage, data=cars_350_train, k=cv_grid_output$k)

cars_350_test = cars_350_test %>%
  mutate(price_350_pred = predict(knn, cars_350_test))

pred_350_test = ggplot(data = cars_350_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.2) +
  labs(title = "Price for Trim=350 of Test data based on Mileage")
pred_350_test

pred_350_test + geom_line(aes(x = mileage, y = price_350_pred), color='red', size=1.5) +
  labs(title = "Fitted Model predicting Price of Trim=350 based on Mileage")
```

```{r echo=FALSE, message=FALSE, warning=FALSE}

cars_65 = cars %>% filter(trim == '65 AMG')

ggplot(data = cars_65) + 
  geom_point(mapping = aes(x = mileage, y = price), color='darkgrey') +
  labs(title = "Price of Trim=65 AMG based on Mileage")

cars_65_split = initial_split(cars_65, prop=0.8)
cars_65_train = training(cars_65_split)
cars_65_test  = testing(cars_65_split)

k_grid = c(2, 4, 6, 8, 10, 15, 20, 25, 30, 35, 40, 45,
           50, 60, 70, 80, 90, 100)

k_grid = seq(2,100, by=1)

cv_65_grid = foreach(k = k_grid, .combine='rbind') %dopar% {
  knn = knnreg(price ~ mileage, data=cars_65_train, k=k)
  rms = rmse(knn, cars_65_test)
  c(k=k, err=rms)
} %>% as.data.frame

head(cv_65_grid)

ggplot(cv_65_grid) + 
  geom_point(aes(x=k, y=err)) +
  labs(title = "RMSE based on k")
  scale_x_log10()

cv_grid_65_output = cv_65_grid %>% filter(err == min(cv_65_grid$err))
cv_grid_65_output$k

knn = knnreg(price ~ mileage, data=cars_65_train, k=cv_grid_output$k)

cars_65_test = cars_65_test %>%
  mutate(price_65_pred = predict(knn, cars_65_test))

pred_65_test = ggplot(data = cars_65_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.2) +
  labs(title = "Price for Trim=350 of Test data based on Mileage")
pred_65_test

pred_65_test + geom_line(aes(x = mileage, y = price_65_pred), color='red', size=1.5)  +
  labs(title = "Fitted Model predicting Price of Trim=65 AMG based on Mileage")

```

* trim = 350 yields a larger optimal k than that in case of trim = 65 AMG
* The sample size for trim = 350 is higher than that for trim = 65. If we have larger sample size, we can afford higher k without the bias being too high. This is because you're averaging the points around the neighborhood. This is about bias-variance trade off. On the contrary, if you have small sample size, you're averaging the data points further away, causing the bias to be high.






